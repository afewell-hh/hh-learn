{
  "title": "Introduction to Kubernetes",
  "slug": "intro-to-kubernetes",
  "difficulty": "beginner",
  "estimated_minutes": 30,
  "version": "v1.30",
  "validated_on": "2025-10-01",
  "pathway_slug": "kubernetes-fundamentals",
  "pathway_name": "Kubernetes Fundamentals",
  "tags": ["kubernetes", "containers", "orchestration"],
  "lab_markdown": "# Lab: Deploy Your First Pod\n\nIn this hands-on lab, you'll learn how to deploy your first Kubernetes pod and interact with it using kubectl.\n\n## Prerequisites\n\n- Access to a Kubernetes cluster\n- kubectl CLI installed and configured\n\n## Step 1: Verify Cluster Connection\n\nFirst, let's verify that your kubectl is properly configured and can connect to your cluster.\n\n```bash\nkubectl cluster-info\n```\n\nYou should see information about your Kubernetes master and services.\n\n## Step 2: Check Current Pods\n\nLet's see what pods are currently running in the default namespace:\n\n```bash\nkubectl get pods\n```\n\nIf this is a fresh cluster, you might not see any pods yet.\n\n## Step 3: Create Your First Pod\n\nLet's create a simple pod running nginx:\n\n```bash\nkubectl run nginx --image=nginx\n```\n\nThis command creates a pod named \"nginx\" using the official nginx Docker image.\n\n## Step 4: Verify Pod Creation\n\nCheck if your pod was created successfully:\n\n```bash\nkubectl get pods\n```\n\nYou should see your nginx pod. It might take a few moments to transition from \"ContainerCreating\" to \"Running\".\n\n## Step 5: Get Detailed Pod Information\n\nTo see more details about your pod:\n\n```bash\nkubectl describe pod nginx\n```\n\nThis shows you detailed information including events, IP address, and container status.\n\n## Step 6: View Pod Logs\n\nCheck the logs from your nginx pod:\n\n```bash\nkubectl logs nginx\n```\n\n## Step 7: Execute Commands in the Pod\n\nYou can execute commands inside the running pod:\n\n```bash\nkubectl exec -it nginx -- /bin/bash\n```\n\nThis opens an interactive shell inside the nginx container. Type `exit` to leave the shell.\n\n## Step 8: Port Forward to Access the Application\n\nForward a local port to the pod:\n\n```bash\nkubectl port-forward nginx 8080:80\n```\n\nNow open your browser and visit `http://localhost:8080` to see the nginx welcome page.\n\n## Step 9: Clean Up\n\nWhen you're done, delete the pod:\n\n```bash\nkubectl delete pod nginx\n```\n\n## Congratulations!\n\nYou've successfully deployed and interacted with your first Kubernetes pod. In the next modules, we'll explore more advanced concepts like deployments, services, and persistent storage.",
  "concepts_markdown": "# Kubernetes Concepts\n\n## What is Kubernetes?\n\nKubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. Originally developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF), Kubernetes has become the de facto standard for container orchestration.\n\n## Key Concepts\n\n### Pods\n\nA **Pod** is the smallest deployable unit in Kubernetes. It represents a single instance of a running process in your cluster. Pods can contain one or more containers that share storage and network resources.\n\nKey characteristics of Pods:\n\n- Pods are ephemeral - they can be created, destroyed, and recreated\n- Each pod gets its own IP address\n- Containers in a pod share the same network namespace\n- Pods are the basic building blocks for deployments\n\n### Nodes\n\nA **Node** is a worker machine in Kubernetes, either a physical or virtual machine. Each node contains the services necessary to run Pods and is managed by the control plane.\n\nEach node runs:\n\n- **kubelet**: Agent that ensures containers are running in pods\n- **container runtime**: Software responsible for running containers (e.g., Docker, containerd)\n- **kube-proxy**: Network proxy that maintains network rules\n\n### Cluster\n\nA **Cluster** is a set of nodes grouped together. Having multiple nodes provides:\n\n- High availability - if one node fails, applications continue running on other nodes\n- Load distribution - workloads can be distributed across multiple machines\n- Scalability - easily add more nodes to handle increased load\n\n### Control Plane\n\nThe **Control Plane** manages the worker nodes and pods in the cluster. It makes global decisions about the cluster (like scheduling) and detects and responds to cluster events.\n\nControl plane components:\n\n- **kube-apiserver**: Frontend for the Kubernetes control plane\n- **etcd**: Key-value store for all cluster data\n- **kube-scheduler**: Assigns pods to nodes\n- **kube-controller-manager**: Runs controller processes\n- **cloud-controller-manager**: Manages cloud-specific control logic\n\n## Why Use Kubernetes?\n\n### 1. Container Orchestration\n\nKubernetes automatically manages the deployment and operation of containers across a cluster of machines, handling:\n\n- Container scheduling and placement\n- Resource allocation\n- Health monitoring\n- Automatic restarts\n\n### 2. Scaling\n\nKubernetes makes it easy to scale applications:\n\n- **Horizontal scaling**: Add or remove pod replicas based on demand\n- **Vertical scaling**: Adjust resource limits for containers\n- **Auto-scaling**: Automatically scale based on CPU usage or custom metrics\n\n### 3. Self-Healing\n\nKubernetes continuously monitors your application and takes corrective action:\n\n- Restarts failed containers\n- Replaces and reschedules containers when nodes die\n- Kills containers that don't respond to health checks\n- Doesn't advertise containers to clients until they're ready\n\n### 4. Service Discovery and Load Balancing\n\nKubernetes provides built-in service discovery and can expose containers using:\n\n- DNS names\n- IP addresses\n- Automatic load balancing across multiple container instances\n\n### 5. Rolling Updates and Rollbacks\n\nKubernetes enables zero-downtime deployments:\n\n- Gradually update application instances\n- Monitor application health during updates\n- Automatically rollback if something goes wrong\n\n## Kubernetes Architecture\n\nKubernetes follows a master-worker architecture:\n\n```\nControl Plane (Master)\n├── API Server\n├── Scheduler\n├── Controller Manager\n└── etcd\n\nWorker Nodes\n├── kubelet\n├── kube-proxy\n└── Container Runtime\n```\n\n## Common Use Cases\n\n1. **Microservices**: Deploy and manage distributed microservices architectures\n2. **CI/CD**: Integrate with continuous integration and deployment pipelines\n3. **Hybrid Cloud**: Run applications across on-premises and cloud environments\n4. **Batch Processing**: Run batch jobs and scheduled tasks\n5. **Machine Learning**: Deploy and scale ML models and training jobs\n\n## Best Practices\n\n1. **Use namespaces** to organize resources and implement resource quotas\n2. **Define resource requests and limits** for all containers\n3. **Implement health checks** (liveness and readiness probes)\n4. **Use labels and selectors** for organization and discovery\n5. **Store configuration in ConfigMaps** and secrets in Secrets\n6. **Use Deployments** instead of bare pods for production workloads\n7. **Implement proper logging and monitoring**\n8. **Follow the principle of least privilege** for RBAC\n\n## Next Steps\n\nNow that you understand the basic concepts, you're ready to:\n\n- Explore Kubernetes Deployments\n- Learn about Services and networking\n- Understand persistent storage with Volumes\n- Dive into advanced topics like StatefulSets and DaemonSets",
  "resources": [
    {
      "title": "Official Kubernetes Documentation",
      "url": "https://kubernetes.io/docs"
    },
    {
      "title": "Kubernetes GitHub Repository",
      "url": "https://github.com/kubernetes/kubernetes"
    },
    {
      "title": "CNCF Kubernetes Certification",
      "url": "https://www.cncf.io/certification/cka/"
    },
    {
      "title": "Kubernetes: Up and Running (Book)",
      "url": "https://www.oreilly.com/library/view/kubernetes-up-and/9781492046523/"
    },
    {
      "title": "Kubernetes Community",
      "url": "https://kubernetes.io/community/"
    }
  ]
}
